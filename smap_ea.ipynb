{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ece813",
   "metadata": {},
   "source": [
    "Accessing via the API per the suggested jupyter notebook was complex. Trying earthaccess python package. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf19581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36768c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auth = earthaccess.login()\n",
    "auth = earthaccess.login(strategy=\"netrc\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b6a33",
   "metadata": {},
   "source": [
    "Using date + time in the format of how it is returned from Nasa EarthData (%Y-%m-%dT%H%M). It has more detail than minutes, but I think that is sufficient for the search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a704becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.today() \n",
    "start_date = today - datetime.timedelta(days=4)\n",
    "start_date = start_date.strftime(\"%Y-%m-%dT%H\")\n",
    "end_date = today.strftime(\"%Y-%m-%dT%H\") # If needed to the second in their format T%H:%M:%SZ\"\n",
    "print(start_date)\n",
    "print(end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d11ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "granules = earthaccess.search_data(\n",
    "    # count=100,\n",
    "    short_name='SPL4SMGP',\n",
    "    version='008',\n",
    "    daac='NSIDC',\n",
    "    provider='NSIDC_ECS',\n",
    "    doi='10.5067/T5RUATAQREF8',\n",
    "    bounding_box=(-126, 24, -65, 50),\n",
    "    temporal=(f\"{start_date}\", f\"{end_date}\"),\n",
    "    sort_key=\"-end_date\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2025f960",
   "metadata": {},
   "source": [
    "This search returns a list of datagranules. I need to sort them and pull out the latest manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f01a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = granules[0]\n",
    "print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44df025",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# latest = max(granules, key=lambda g: datetime.fromisoformat(g.temporal_coverage[\"end\"]))\n",
    "url = item.data_links()[0]\n",
    "print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740822b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can download directly this way if desired\n",
    "# earthaccess.download(data, \"./data/smap/\", provider='NSIDC_ECS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a486c98",
   "metadata": {},
   "source": [
    "Using Earth access I can get a file-like object HTTPFileSystem. But it can't be opened directly with xarray (h5netcdf gives a \"unhashable type list\" error, and netcdf4 cannot read bytes or file-like object). I can access the url by using .data_links()[0] with the data search result. \n",
    "\n",
    "I tried using: \n",
    "\n",
    "`fs = fsspec.filesystem(\"https\")\n",
    "with fs.open(url, mode=\"rb\") as f:\n",
    "    ds_smap = xr.open_dataset(f, engine=\"h5netcdf\")`\n",
    "\n",
    "But this gave a 401 unauthorized error. \n",
    "\n",
    "Earthaccess provides a earthaccess.get_fsspec() to authenticate using the url. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7525ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = earthaccess.get_fsspec_https_session()\n",
    "# url = granules[0].data_links()[0] \n",
    "with fs.open(url, mode=\"rb\") as f:\n",
    "    ds_smap = xr.open_dataset(f, engine=\"h5netcdf\", group='Geophysical_Data')\n",
    "    ds_vars_smap = ds_smap[[\"sm_surface_wetness\", \"vegetation_greenness_fraction\", \"surface_temp\"]]\n",
    "    ds_vars_smap.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d0723",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(url)\n",
    "ds_vars_smap[\"sm_surface_wetness\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06850a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_vars_smap = ds_smap[[\"sm_surface_wetness\", \"vegetation_greenness_fraction\", \"surface_temp\"]]\n",
    "ds_vars_smap.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57710bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sw = ds_vars_smap[\"sm_surface_wetness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82116650",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6386f6c",
   "metadata": {},
   "source": [
    "## workflow when downloading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4071fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smap_20250604 = xr.open_mfdataset(httpfile, engine='h5netcdf') #need to have dask installed to use mfdataset. Couldn't get \"open_dataset\" to work\n",
    "ds_smap = xr.open_dataset(\"data/smap/SMAP_L4_SM_gph_20250604T223000_Vv8011_001.h5\", engine=\"h5netcdf\", group='Geophysical_Data')\n",
    "ds_smap_all = xr.open_dataset(\"data/smap/SMAP_L4_SM_gph_20250604T223000_Vv8011_001.h5\", engine=\"h5netcdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef03cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_smap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25923af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_smap_combined = ds_smap.merge(ds_smap_all[['cell_column', 'cell_row']]) #The data is on a projected grid (EASE 2.0), so I select the row and column rather than lat/long. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d454b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_smap_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4338fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_smap_us = ds_smap.sel(y=slice(5556000, 2667000), x=slice(-14010000, -7223000)) Worked for original, but I think it needs to be by row/column for the geophysical_data\n",
    "import math \n",
    "\n",
    "pixel_size = 9024.13\n",
    "y_min = int(math.ceil(2667000 / pixel_size))\n",
    "y_max = int(math.ceil(5556000 / pixel_size))\n",
    "x_min = int(math.ceil(-14010000 / pixel_size))\n",
    "x_max = int(math.ceil(-7223000 / pixel_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e6091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_smap_us = ds_smap.sel(y=slice(y_min, y_max), x=slice(x_min, x_max)) # slicing by cells. Worked before based on ds without coordinates. \n",
    "# ds_smap_combined_us = ds_smap_combined.sel(y=slice(y_min, y_max), x=slice(x_min, x_max)) #Didn't work, becuase it now has coordinates.\n",
    "ds_smap_combined_us = ds_smap_combined.sel(y=slice(5656000, 2667000), x=slice(-12310000, -6323000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e926ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_smap_combined_us['sm_surface_wetness'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fca56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_combined_6931 = ds_smap_combined_us.rio.write_crs(\"EPSG:6933\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b588dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_combined_6931['sm_surface_wetness'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ba9053",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_smap_analysis = ds_smap_combined_us[['sm_surface', 'sm_surface_wetness', 'precipitation_total_surface_flux', 'overland_runoff_flux']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2198c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_smap_combined_us['sm_surface_wetness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ece541",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_smap_sw = ds_smap_combined_us['sm_surface_wetness']\n",
    "# ds_smap_sw_masked = ds_smap_sw.where(ds_smap_sw != ds_smap_sw.attrs['fmissing_value']) Didn't seem to do anything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22964f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_smap_5070 = ds_smap_analysis.rio.reproject(\"EPSG:5070\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb5a1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_smap_5070['sm_surface_wetness'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee8eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_smap_5070.to_netcdf(\"data/smap/ds_smap_5070.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "can-i-ride-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
